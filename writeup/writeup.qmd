---
title: "Replication of Robot Voices in Daily Life: Vocal Human-Likeness and Application Context as Determinants of User Acceptance by Simon Schreibelmayr and Martina Mara (2022, Frontiers in Psychology)"
author: "Noah Khaloo"
date: "2024-10-10"
format: html
editor: visual
---

## Introduction

This project will be a conceptual replication of Schreibelmayr and Mara (2022). Specifically, we will be in assessing whether their results generalize to more modern voice-AI technology. One of the major findings of their paper is that, as perceived 'human-likeness' of a voice-AI system goes up, the more pleasant humans find it. In addition, an increase in human-likeness also corresponds to an increase in anthropomorphism towards the voice-AI. Schreibelmayr and Mara (2022) results goes against the so-called Uncanny Valley hypothesis, which predicts that the perception of 'pleasantness' of a machine-agent should go up linearly with perceived-human likeness, until it reaches a certain point where users find the machine 'eerie' or 'repulsive' (Mori, 1970). The follow up study that we will conduct is not only important in terms of replication, but it also holds theoretical significance, as it will test whether Schreibelmayr and Mara's (2022) results hold in the modern-day, where voice-AI technology is becoming increasingly advanced and capable (Fernandes and Oliveira, 2021). In other words, Schreibelmayr and Mara's (2022) show that user interaction with voice-AI does not seem to be conditioned by the Uncanny Valley Effect, however, this may not hold true in the modern-day. Furthermore, Schreibelmayr and Mara (2022) used a real human as one of their stimuli (though they told participants that this was a voice-AI, and modified the voice to get rid of pauses and breaths). We will not be doing this, given how human-like voice-AI technology has become. Instead, our results will be contained within the voice-AI space. Thus, our findings will expand upon Schreibelmayr and Mara (2022)'s results even further by showing how it replicates when the *only* stimuli are voice-AI.

This is in-line with my research interests, which revolve primarily around how humans can pick up on key information by assessing the voice quality of their interlocuter. In other words, human's are extremely skilled at picking up on sociocultural information just by hearing the sound of someone's voice, regardless of what they are saying. In this same way, we are also easily able to pick up on more abstract qualities of our interlocutor, such as emotion or mental state. This project falls in line with my research interest in that it begins to assess whether we are able to make these same sociocultural judgments about voice-AI. Furthermore, this project dives deeper into how well human's are able to converge on the "human-likeness" of a voice-AI system, and how this quality affects our perception of the system itself. This project also falls in line with another interest of mine, which involves promoting AI safety by better understanding our interactions with these increasingly complex systems.

## Procedure

This project will closely follow the procedure laid out in Schreibelmayr and Mara (2022). The participants will be taking a survey where they will be answering demographic information about themselves, and filling in a personality questionnaire. They will then be hearing the speech of a pre-recorded Talk to Speech (TTS) system (which participants will be randomly assigned to). Note that, like Schreibelmayr and Mara (2022), the participants will not be interacting with the system in any way other than hearing it, so we will be using an TTS system that we've pre-recorded to simulate a real voice-AI agent. After hearing the voice, the participants will be rating the system based on the criteria Schreibelmayr and Mara (2022) have set forth in their paper.

The major difference between this study and Schreibelmayr and Mara (2022) is the TTS systems we will be using. In other words, Schreibelmayr and Mara (2022) used Amazon 'Polly' (Polly, 2019) and Microsoft 'Hedda' (Hedda, 2019). Since we don't have access to older versions of TTS technology, we will be using the 'Alloy' (female) voice from <https://ttsmp3.com/ai>, the 'Kimberly' (US English) voice from <https://ttstool.com/>, and the 'Little old lady' voice from <https://discordier.github.io/sam/>. As the state-of-the-art system, we will be using the 'Alloy' voice from OpenAI TTS (<https://platform.openai.com/docs/guides/text-to-speech/overview>). The goal is to use voices that converge on perceived gender, and dialect.

Unlike Schreibelmayr and Mara (2022), we will not be doing any modifications to the speech to make them sound less human-like (see **Voice Stimuli** in Schreibelmayr and Mara (2022)). In addition, we will be conducting the experiment in English, as opposed to Schreibelmayr and Mara (2022) who did it in German.

## Challenges

1.  Schreibelmayr and Mara (2022) did their study using a survey, but it was conducted in a lab. Ours will have to be taken remotely, which makes it harder to minimize distractions for our participants.
2.  Our participants are likely only going to be undergraduates from a similar age range (maybe 18-23 y.o.), which may skew results.
3.  It may be difficult to find the exact personality questions Schreibelmayr and Mara (2022) asked in their survey (especially since it was in German). A part of me wants to just omit this part, since it does not relate much to the broad theoretical implications this paper has (which relates to the Uncanny Valley effect and voice-AI).

## Citations

Fernandes, T., & Oliveira, E. (2021). Understanding consumers’ acceptance of automated technologies in service encounters: Drivers of digital voice assistants adoption. Journal of Business Research, 122, 180-191.

Mori, M. (1970). Bukimi no tani \[the uncanny valley\]. Energy 7, 33–35.

Schreibelmayr, S., & Mara, M. (2022). Robot voices in daily life: Vocal human-likeness and application context as determinants of user acceptance. *Frontiers in Psychology*, *13*, 787499.
